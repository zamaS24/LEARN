{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "import numpy as np \n",
    "from torch import nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of t :  torch.Size([4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.2382], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_l = [1,2,3,4]\n",
    "x = torch.Tensor(x_l)\n",
    "t = torch.Tensor([\n",
    "    [1], \n",
    "    [2], \n",
    "    [3], \n",
    "    [4]\n",
    "])\n",
    "print('shape of t : ', t.shape)\n",
    "# it's by working everyday and advancing everyday, that's what computer science, is. I mean \n",
    "# to be good at it you have to do it this way lol thank me later \n",
    "\n",
    "model = nn.Linear(4,1)\n",
    "\n",
    "model(torch.Tensor([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6., 8.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "\n",
    "# this one also should be a row vector, becasue our X is \n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l is :  tensor(0.6250)\n"
     ]
    }
   ],
   "source": [
    "input_size = 1\n",
    "output_size = 1 \n",
    "\n",
    "# since the input size is 1 he will expect a tensor of size 1, or an array of tensors of Size 1\n",
    "# but if you forwards an array of size 4, as if you said here's a sample of input_features = 4, \n",
    "# but we know that our features are 1 \n",
    "\n",
    "model = nn.Linear(\n",
    "    input_size, \n",
    "    output_size\n",
    ")\n",
    "\n",
    "y_pred = torch.tensor([[1], [2]], dtype=torch.float32)\n",
    "\n",
    "model(y_pred)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# y_true should have the same size as y_predicted \n",
    "y_true = torch.tensor([0.5, 1.0], dtype=torch.float32)\n",
    "\n",
    "y_true = y_true.view(y_true.shape[0], 1) # this is like redimensioning the array ! \n",
    "\n",
    "\n",
    "l = loss(y_pred, y_true)\n",
    "\n",
    "print('l is : ', l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1], dtype=torch.float32)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([], dtype=torch.float32)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1], dtype=torch.float32)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 0])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([[]], dtype=torch.float32)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([[1,2], [3,4]], dtype=torch.float32)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = nn.Linear(\n",
    "    128*128,\n",
    "    54\n",
    ")\n",
    "\n",
    "\n",
    "x = torch.tensor([1], dtype=torch.float32)\n",
    "\n",
    "\n",
    "# model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad None\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.tensor([1,2,3], dtype=torch.float32,  requires_grad=True)\n",
    "\n",
    "y = 2*x +1\n",
    "\n",
    "z = y*4\n",
    "\n",
    "\n",
    "print('x.grad',x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.backward of tensor([12., 20., 28.], grad_fn=<MulBackward0>)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1,2,3,5],\n",
    "    [2,3,3,4],\n",
    "    [1,6,4,4]\n",
    "])\n",
    "\n",
    "torch.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image before : (256, 256)\n",
      "type of img  <class 'PIL.Image.Image'>\n",
      "shape of image after transformations : torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Image Classification\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "\n",
    "# Define the size of the image\n",
    "width, height = 256, 256\n",
    "\n",
    "# Create a random numpy array representing the image\n",
    "img = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n",
    "\n",
    "# Convert the numpy array to a PIL image\n",
    "img = Image.fromarray(img)\n",
    "\n",
    "print('shape of image before :', img.size)\n",
    "\n",
    "print('type of img ', type(img))\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.333)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "img = transform(img)\n",
    "\n",
    "print('shape of image after transformations :', img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class MyDataset(Dataset): \n",
    "\n",
    "    def __init__(self) -> None: \n",
    "        super(MyDataset, self).__init__()\n",
    "\n",
    "        xy = np.random.uniform(0, 1, size=(200,2))\n",
    "\n",
    "        self.x = torch.from_numpy(xy[:,:1])\n",
    "        self.y = torch.from_numpy(xy[:, 1:])\n",
    "\n",
    "        self.len = xy.shape[0]\n",
    "\n",
    "\n",
    "    # I guess this should return, features and labels \n",
    "    # you think about training here \n",
    "    def __getitem__(self, index): \n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "\n",
    "    def __len__(self): \n",
    "        return self.len\n",
    "\n",
    "# you need to define your data loader right \n",
    "\n",
    "mydataset = MyDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=mydataset, \n",
    "    shuffle=True, \n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model \n",
    "def train_model(model, optimizer, criterion, epochs ): \n",
    "\n",
    "    best_whs = model.get_state_dict()\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        \n",
    "\n",
    "        for mode in range ['train', 'val']: \n",
    "        \n",
    "            if mode == 'train': \n",
    "                model.train()\n",
    "            else: \n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0\n",
    "            running_acc = 0     # not a classification task S\n",
    "\n",
    "            # loop over the batches \n",
    "            for (inputs, labels) in dataloader: \n",
    "\n",
    "                with torch.set_grad_enabled(mode =='train'): \n",
    "                    out = model(inputs)\n",
    "                    # result is of shape (bs, 1)\n",
    "                    loss = criterion(out, labels) # MSE\n",
    "                    \n",
    "\n",
    "                if (mode =='train'): \n",
    "                    # update weights\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "\n",
    "                running_loss += running_loss * out.size(0)\n",
    "\n",
    "                # end of batch loop \n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.random.uniform(0, 1, size=(200,2))\n",
    "xy.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.tensor([1], dtype=torch.float32, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of out :  torch.Size([3, 1])\n",
      "shape  of y_true torch.Size([3])\n",
      "shape of y_true now  torch.Size([3, 1])\n",
      "loss is : tensor([[29.],\n",
      "        [28.],\n",
      "        [27.]], grad_fn=<SubBackward0>)\n",
      "mean loss i s:  tensor(28., grad_fn=<MeanBackward0>)\n",
      "w1.grad :  None\n",
      "w1 grad: tensor([[0.3333, 0.6667, 1.0000, 1.3333],\n",
      "        [0.3333, 0.6667, 1.0000, 1.3333],\n",
      "        [0.3333, 0.6667, 1.0000, 1.3333]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "w1 = torch.tensor(\n",
    "   [[1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4]], \n",
    "    dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "# shape : (4,3)\n",
    "\n",
    "x = torch.tensor(\n",
    "    [\n",
    "        [1],\n",
    "        [2],\n",
    "        [3],\n",
    "        [4]\n",
    "    ],\n",
    "    dtype=torch.float32, requires_grad=True\n",
    ")\n",
    "\n",
    "\n",
    "out = F.relu(w1 @ x)\n",
    "\n",
    "y_true = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "\n",
    "print('shape of out : ', out.shape)\n",
    "print('shape  of y_true', y_true.shape)\n",
    "\n",
    "y_true = y_true.view(-1, 1)\n",
    "print('shape of y_true now ', y_true.shape)\n",
    "\n",
    "loss = torch.sub(out,y_true)\n",
    "mean_loss = loss.mean()\n",
    "\n",
    "print('loss is :', loss)\n",
    "print('mean loss i s: ', mean_loss)\n",
    "\n",
    "print('w1.grad : ', w1.grad)\n",
    "\n",
    "mean_loss.backward()\n",
    "\n",
    "print('w1 grad:', w1.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule one : always your data gotta be of shape like : (bs, *infeatures)\n",
    "# your y_true should match the same output of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use tensorboard for that?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
